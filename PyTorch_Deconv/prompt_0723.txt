# ZS-DeconvNet Pure Deconvolution - Minimal Implementation

I want to implement a streamlined pure deconvolution network using PyTorch Lightning for fluorescence microscopy image enhancement. This implementation focuses on deconvolution with 2x super-resolution using self-supervised learning with PSF-based physics constraints.

Please generate the following files with minimal, production-ready code:

## 1. config.yaml
Configuration file with essential parameters only:
```yaml
# Model configuration
model:
  input_channels: 1
  output_channels: 1
  conv_block_num: 4
  conv_num: 3
  upsample_flag: true
  insert_xy: 16

# Loss function configuration  
loss:
  hessian_weight: 0.02     # Only essential regularization
  use_mse: false           # Use MAE loss
  upsample_flag: true
  insert_xy: 16

# Optimizer configuration
optimizer:
  lr: 0.00005
  weight_decay: 0.00001

# Data configuration
data:
  batch_size: 4
  patch_size: 128
  insert_xy: 16
  num_workers: 4
  train_val_split: 0.8

# PSF configuration
psf:
  target_dx: 0.0313
  target_dy: 0.0313
  psf_dx: null
  psf_dy: null

# Trainer configuration
trainer:
  max_epochs: 100
  precision: 32
  gradient_clip_val: 0.5
```

## 2. deconv_unet.py
Single-stage U-Net model for pure deconvolution:
- ConvBlock: Downsampling with conv_num layers + MaxPool2d
- ConcatBlock: Upsampling with nearest neighbor + concatenation + conv_num layers  
- DeconvUNet: Main model with conv_block_num encoder/decoder levels
- Channel progression: 32, 64, 128, 256 for 4-level architecture
- Final layers: Optional 2x upsampling + 3 convolution layers
- Remove unused forward_with_crop method

## 3. psf_loss.py
Simplified PSF-based physics loss:
- PSFConvolutionLoss: Core loss applying PSF convolution to predictions
  - Apply PSF convolution using F.conv2d with 'same' padding
  - Handle 2x upsampling: downsample convolved result by 0.5
  - Crop output to match target size using insert_xy
  - Support only MAE reconstruction loss
- Hessian regularization: _compute_hessian_loss method only
- Remove TV, L1, and MultiScale loss implementations
- Simple create_loss_function factory

## 4. psf_utils.py  
Complete PSF processing utilities (keep all current functionality):
- PSFProcessor class with full implementation
- prctile_norm function
- load_and_process_psf with complete interpolation and processing
- gaussian_1d and psf_estimator_2d functions
- All current PSF handling capabilities preserved

## 5. datamodule.py
Simplified data loading:
- TiffSliceDataset class:
  - Support 2D and 3D TIFF files with slice-based indexing
  - Extract random patches of patch_size + 2*insert_xy
  - Basic normalization using prctile_norm  
  - Remove data augmentation (_apply_augmentation method)
  - Return input/target pairs for self-supervised learning
- DeconvDataModule class:
  - Simplified setup method for train/val datasets
  - Basic train_dataloader and val_dataloader methods

## 6. lightning_module.py
Minimal Lightning module following Katsu's style:
```python
import pytorch_lightning as pl
import torch
from torch.optim import Adam

class DeconvolutionLightningModule(pl.LightningModule):
    def __init__(self, 
                 model_config: dict,
                 loss_config: dict, 
                 optimizer_config: dict,
                 psf_path: str,
                 psf_config: dict = None):
        super().__init__()
        self.save_hyperparameters()
        
        # Initialize model and PSF processor
        self.model = None  # DeconvUNet from deconv_unet.py
        self.psf_processor = None  # PSFProcessor from psf_utils.py
        self.loss_fn = None  # Initialized in setup()

    def setup(self, stage=None):
        # Load PSF and initialize loss function
        ...

    def training_step(self, batch, batch_idx):
        # Basic training: forward pass, loss calculation, logging
        ...

    def validation_step(self, batch, batch_idx):
        # Basic validation: forward pass, loss calculation, logging
        ...

    def configure_optimizers(self):
        # Return Adam optimizer only
        ...
```
Requirements:
- Remove image logging functionality completely
- Remove custom checkpoint methods
- Remove epoch end methods and loss history tracking
- Remove learning rate scheduler support
- Basic loss logging only (train_loss, val_loss)

## 7. train.py
Simplified training script:
- Load configuration from config.yaml
- Create DeconvDataModule and DeconvolutionLightningModule
- Basic Lightning Trainer setup with config parameters
- Remove complex callbacks (no early stopping, no custom checkpoints)
- Save final model as 'final_model.ckpt'
- Arguments: --config, --psf_path, --data_dir, --output_dir, --gpus

## 8. infer.py
Streamlined inference script:
- Load model from checkpoint 
- Two processing methods only:
  - process_slice_whole: For normal-sized images
  - process_slice_tiled: Simple tiling with --tile_size and --overlap
- Remove complex original tiling method (process_slice_original_tiling)
- Process 2D/3D TIFF files with proper 2x super-resolution output
- Arguments: --checkpoint, --input_dir, --output_dir, --device, --tile_size, --overlap

## 9. File Structure
All files should be created at the root level (no subdirectories):
```
deconv_unet.py          # Model architecture
psf_loss.py            # Loss functions
psf_utils.py           # PSF processing utilities
datamodule.py          # Data loading
lightning_module.py    # Lightning module
train.py              # Training script
infer.py              # Inference script
config.yaml           # Configuration
requirements.txt      # Dependencies
```

## 10. requirements.txt
Essential packages only:
```
torch>=2.0.0
torchvision>=0.15.0
pytorch-lightning>=2.0.0
tifffile>=2023.4.12
numpy>=1.24.0
scipy>=1.10.0
opencv-python>=4.7.0
PyYAML>=6.0
tqdm>=4.65.0
```

## 11. Data Structure
```
Data/
├── Train/              # Training TIFF images
├── InferenceInput/     # Input images for inference  
├── InferenceResult/    # Output directory (auto-created)
├── Output/             # Training outputs and checkpoints
└── PSF/               # PSF files (.tif format)
```

## Technical Requirements:
1. **Core functionality only**: Single-stage U-Net for deconvolution with 2x super-resolution
2. **Essential loss**: PSF convolution loss + Hessian regularization (0.02 weight)
3. **Simplified training**: Basic Lightning trainer without complex callbacks
4. **Essential inference**: Whole image and simple tiling methods only
5. **No visualization**: Remove all image logging and TensorBoard visualization
6. **No augmentation**: Remove data augmentation features
7. **Fixed parameters**: Minimize configurable options for stability
8. **3D support**: Process 3D TIFF files slice by slice (Z, H, W) → (Z, 2H, 2W)

## Success Criteria:
- Generated code must be executable without modifications
- All files created at root level with simple imports (e.g., `from deconv_unet import DeconvUNet`)
- Training should start directly with: `python train.py --config config.yaml --psf_path Data/PSF/psf_file.tif --data_dir Data --output_dir Data/Output --gpus 1`
- Inference should work with: `python infer.py --checkpoint Data/Output/final_model.ckpt --input_dir Data/InferenceInput --output_dir Data/InferenceResult --device auto`
- No runtime errors or missing dependencies
