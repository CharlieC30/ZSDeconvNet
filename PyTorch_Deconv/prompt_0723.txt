ZS-DeconvNet Pure Deconvolution with PyTorch Lightning 2.0+

I want to implement a pure deconvolution network using PyTorch Lightning for fluorescence microscopy image enhancement. This implementation focuses on deconvolution with 2x super-resolution using self-supervised learning with PSF-based physics constraints.

Please help me generate the following .py files according to the specifications below:

1. config.yaml
    Configuration file containing all hyperparameters and settings:
    model:
      input_channels: 1
      output_channels: 1
      conv_block_num: 4
      conv_num: 3
      upsample_flag: true
      insert_xy: 16

    loss:
      tv_weight: 0.0
      hessian_weight: 0.02
      l1_weight: 0.0
      use_mse: false
      upsample_flag: true
      insert_xy: 16

    optimizer:
      lr: 0.00005
      weight_decay: 0.00001

    scheduler:
      type: "step"
      step_size: 10000
      gamma: 0.5

    data:
      batch_size: 4
      patch_size: 128
      insert_xy: 16
      num_workers: 4
      train_val_split: 0.8

    psf:
      target_dx: 0.0313
      target_dy: 0.0313
      psf_dx: null
      psf_dy: null

    trainer:
      max_epochs: 100
      precision: 32
      gradient_clip_val: 0.5
      accumulate_grad_batches: 1
      val_check_interval: 1.0
      log_every_n_steps: 50

    checkpoint:
      monitor: "val_loss"
      mode: "min"
      save_top_k: 3
      save_last: true

    early_stopping:
      enabled: false
      monitor: "val_loss"
      mode: "min"
      patience: 15
      min_delta: 0.001

    log_images: true
    log_every_n_epochs: 10

2. src/models/deconv_unet.py
    Define the single-stage U-Net model architecture for pure deconvolution.
    Requirements:
    - ConvBlock: Downsampling block with conv_num convolution layers + MaxPool2d
    - ConcatBlock: Upsampling block with nearest neighbor upsampling + concatenation + conv_num convolution layers
    - DeconvUNet: Main model class with conv_block_num encoder/decoder levels
    - Channel progression: 32, 64, 128, 256 for 4-level architecture
    - Middle layers: Expand and contract channels
    - Final layers: Optional 2x upsampling + 3 convolution layers to output_channels
    - forward_with_crop method: Remove padded regions based on insert_xy
    - create_deconv_unet factory function

3. src/losses/psf_loss.py
    Implement PSF-based physics loss functions.
    Requirements:
    - PSFConvolutionLoss: Main loss class applying PSF convolution to predictions
      - Apply PSF convolution using F.conv2d with 'same' padding
      - Handle upsampling: downsample convolved result by 0.5 if upsample_flag=True
      - Crop output to match target size using insert_xy
      - Support MSE or MAE reconstruction loss
      - IMPORTANT: Register PSF buffer with persistent=False to avoid state_dict issues
        Example: self.register_buffer('psf', psf, persistent=False)
    - Total Variation regularization: _compute_tv_loss method
    - Hessian regularization: _compute_hessian_loss method (second derivatives)
    - L1 regularization: Direct L1 penalty on predictions
    - DeconvolutionLoss: Wrapper class combining all loss terms
    - MultiScaleLoss: Multi-scale loss for improved training stability
    - create_loss_function: Factory function for loss instantiation

4. src/utils/psf_utils.py
    PSF processing utilities.
    Requirements:
    - PSFProcessor class:
      - __init__: Store PSF file path
      - load_psf: Load and process PSF with target shape and sampling matching
      - Handle TIFF PSF files with proper normalization
      - Interpolation for sampling rate matching between PSF and target
    - prctile_norm function: Percentile-based normalization (0.1%, 99.9%)
    - load_and_process_psf: Standalone function for direct PSF loading

5. src/data/datamodule.py
    Data loading and preprocessing.
    Requirements:
    - TiffSliceDataset class:
      - Support both 2D and 3D TIFF files
      - Slice-based indexing for 3D data
      - Extract random patches of patch_size + 2*insert_xy
      - Normalization using prctile_norm
      - Return input/target pairs for self-supervised learning
    - DeconvDataModule class (PyTorch Lightning DataModule):
      - setup method: Create train/val datasets from directory structure
      - train_dataloader, val_dataloader methods
      - Support train_val_split configuration

6. src/models/lightning_module.py
    Create a Lightning module class as shown below:

    import pytorch_lightning as pl
    import torch
    import torch.nn as nn
    from torch.optim import Adam
    from torch.optim.lr_scheduler import StepLR, ExponentialLR
    import numpy as np

    class DeconvolutionLightningModule(pl.LightningModule):
        def __init__(self, 
                     model_config: dict,
                     loss_config: dict,
                     optimizer_config: dict,
                     psf_path: str,
                     psf_config: dict = None,
                     scheduler_config: dict = None,
                     log_images: bool = False,
                     log_every_n_epochs: int = 10):
            super().__init__()
            self.save_hyperparameters()
            
            # Initialize model from src.models.deconv_unet
            self.model = None  # Will be replaced with DeconvUNet
            
            # PSF processor and loss function
            self.psf_processor = None  # Will be replaced with PSFProcessor
            self.loss_fn = None  # Will be initialized in setup()
            
            # Store configs
            self.model_config = model_config
            self.loss_config = loss_config
            self.optimizer_config = optimizer_config
            self.scheduler_config = scheduler_config
            
            # Loss history tracking
            self.train_loss_history = []
            self.val_loss_history = []

        def setup(self, stage=None):
            # Load and process PSF, initialize loss function
            ...

        def forward(self, x):
            # Forward pass through the model
            ...

        def training_step(self, batch, batch_idx):
            # Implement training logic: forward pass, loss calculation, history tracking
            ...

        def validation_step(self, batch, batch_idx):
            # Implement validation logic: forward pass, loss calculation, history tracking
            ...

        def on_train_epoch_end(self):
            # Log average training loss
            ...

        def on_validation_epoch_end(self):
            # Log average validation loss
            ...

        def configure_optimizers(self):
            # Configure Adam optimizer and optional scheduler
            ...

        def load_state_dict(self, state_dict, strict=True):
            # IMPORTANT: Custom state dict loading to handle PSF buffer issues
            # Remove problematic PSF buffer keys and use strict=False
            ...

        def on_save_checkpoint(self, checkpoint):
            # IMPORTANT: Custom checkpoint saving to remove PSF buffer
            # Prevents state_dict loading errors in distributed training
            ...

    Requirements:
    - Loss function initialization in setup() using PSF
    - Loss history tracking in train_loss_history and val_loss_history lists
    - Support for StepLR and ExponentialLR schedulers
    - Simplified logging without image visualization
    - CRITICAL: Custom state_dict handling methods for PSF buffer compatibility

7. train.py
    This script should:
    - Load configuration from config.yaml using yaml.safe_load
    - Create PSF path from command line argument --psf_path
    - Import and instantiate DeconvDataModule with data configuration
    - Import and instantiate DeconvolutionLightningModule with all configurations
    - Create Lightning Trainer with all trainer configuration from YAML
    - Support --resume argument for checkpoint resuming
    - Save final model as 'final_model.ckpt'
    Command line arguments: --config, --psf_path, --data_dir, --output_dir, --gpus, --resume

8. infer.py
    This script should:
    - Load trained model from checkpoint using --checkpoint argument
    - Support both standard inference and tiled inference for large images
    - Two tiling methods:
      - Standard tiling: --tile_size and --overlap parameters
      - Original tiling: --use_original_tiling with --num_seg_window_x/y and --overlap_x/y
    - Handle device placement automatically (--device auto)
    - Process input directory with TIFF files
    - Save results as '*_deconvolved.tif' with 2x resolution
    - Proper image cropping and normalization
    - CRITICAL: 3D TIFF Processing Requirements:
      - For 3D TIFF files (shape: Z, H, W), process ALL slices individually
      - Each 2D slice undergoes 2x super-resolution deconvolution
      - Output 3D TIFF with shape (Z, 2H, 2W) - all slices processed
      - NEVER process only middle slice or subset of slices
      - Maintain consistency with training: slice-based processing
      - Use tqdm progress bar for 3D processing feedback
    Command line arguments: --checkpoint, --input_dir, --output_dir, --device, tiling parameters

9. src/__init__.py
    Package initialization file (can be minimal comment).

10. src/models/__init__.py
    Export model classes:
    from .deconv_unet import DeconvUNet, create_deconv_unet
    from .lightning_module import DeconvolutionLightningModule

11. src/data/__init__.py
    Export data classes:
    from .datamodule import DeconvDataModule, TiffSliceDataset

12. src/losses/__init__.py
    Export loss classes:
    from .psf_loss import PSFConvolutionLoss, DeconvolutionLoss, MultiScaleLoss, create_loss_function

13. src/utils/__init__.py
    Export utility functions:
    from .psf_utils import PSFProcessor, load_and_process_psf, prctile_norm

14. requirements.txt
    List all required packages:
    torch>=2.0.0
    torchvision>=0.15.0
    pytorch-lightning>=2.0.0
    tifffile>=2023.4.12
    numpy>=1.24.0
    scipy>=1.10.0
    opencv-python>=4.7.0
    matplotlib>=3.7.0
    scikit-image>=0.20.0
    PyYAML>=6.0
    tqdm>=4.65.0

15. README.md
    Documentation with:
    - Installation instructions
    - Data structure requirements
    - Training usage examples
    - Inference usage examples
    - Key parameter descriptions
    - Troubleshooting guide

16. Data Structure
    Expected data organization:
    Data/
    ├── Train/              # Training TIFF images (2D or 3D TIFF stacks)
    ├── InferenceInput/     # Input images for inference (2D or 3D TIFF stacks)
    ├── InferenceResult/    # Output directory (auto-created)
    ├── Output/             # Training outputs and checkpoints
    └── PSF/               # PSF files (.tif format)

    TIFF File Format Requirements:
    - 2D TIFF: Single image with shape (H, W)
    - 3D TIFF: Stack of 2D slices with shape (Z, H, W)
    - All slices in 3D TIFF must have consistent dimensions
    - Training treats each 2D slice as independent sample
    - Inference processes all slices and maintains 3D structure

Technical Notes:
- The model should use single-stage U-Net for deconvolution only (no denoising stage)
- PSF convolution loss is the core physics constraint
- Hessian regularization (weight 0.02) is critical for edge preservation
- Support both 2D single images and 3D TIFF stacks (slice-based processing)
- Automatic device selection with proper error handling
- All trainer parameters must be configurable via YAML
- Loss history tracking for analysis and debugging
- Multi-scale loss capability for improved convergence
- Two inference modes for different image sizes and quality requirements

Critical Implementation Notes for PSF Buffer Handling:
- PSF buffers must use persistent=False in register_buffer() to prevent state_dict issues
- Lightning modules must implement custom load_state_dict() and on_save_checkpoint() methods
- Use strict=False in state_dict loading to handle missing PSF buffer keys
- These measures ensure compatibility with multi-GPU distributed training
- PSF is reloaded in setup() method, so persistent storage is unnecessary
- Failure to implement these safeguards will cause training completion errors

3D TIFF Processing Requirements:
- Training Phase: 3D TIFF files are automatically split into individual 2D slices
- Each 2D slice becomes an independent training sample with patch extraction
- Inference Phase: Must process ALL slices in 3D TIFF files, not just middle slice
- Input 3D shape (Z, H, W) → Output 3D shape (Z, 2H, 2W) after 2x super-resolution
- Maintain consistency: same slice-wise processing in both training and inference
- Use progress indicators (tqdm) for multi-slice processing feedback
- Never implement shortcuts that process only subset of available slices

Note: When we run train.py, training should start directly using all components specified above without any further modifications.